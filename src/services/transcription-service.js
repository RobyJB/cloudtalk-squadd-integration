import OpenAI from 'openai';
import fs from 'fs/promises';
import path from 'path';
import fetch from 'node-fetch';
import { log, logError } from '../logger.js';
import { execSync } from 'child_process';

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

// Custom vocabulary for Squadd call transcription accuracy
const CUSTOM_VOCABULARY = [
  // Squadd specific terms
  'Squadd', 'CRM', 'Workflow', 'Automazioni', 'Appuntamento',

  // Competitor software mentioned in calls
  'GoHighLevel', 'Delera', 'Leadfather', 'Arcanis', 'Growi', 'Unique.ai',

  // Common business terms in Italian B2B calls
  'cliente', 'preventivo', 'offerta', 'contratto', 'fattura', 'scadenza',
  'riunione', 'appuntamento', 'telefonate', 'email', 'WhatsApp',

  // Sales and CRM terminology
  'lead', 'prospect', 'pipeline', 'funnel', 'software', 'piattaforma',
  'abbonamento', 'SaaS', 'demo', 'trial', 'budget', 'team vendita',
  'gestione', 'pubblicit√†', 'marketing', 'automazione', 'flusso lavoro'
];

/**
 * Download audio file from URL
 * @param {string} audioUrl - URL of the audio file
 * @returns {Promise<{success: boolean, filePath?: string, error?: string}>}
 */
async function downloadAudio(audioUrl) {
  try {
    log(`üéµ Downloading audio from: ${audioUrl}`);

    const response = await fetch(audioUrl);
    if (!response.ok) {
      throw new Error(`HTTP ${response.status}: ${response.statusText}`);
    }

    // Create temp directory if it doesn't exist
    const tempDir = path.join(process.cwd(), 'temp-audio');
    await fs.mkdir(tempDir, { recursive: true });

    // Generate unique filename
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `recording_${timestamp}.wav`;
    const filePath = path.join(tempDir, filename);

    // Download and save file
    const arrayBuffer = await response.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);
    await fs.writeFile(filePath, buffer);

    log(`‚úÖ Audio downloaded to: ${filePath} (${buffer.length} bytes)`);

    return {
      success: true,
      filePath: filePath
    };

  } catch (error) {
    logError(`‚ùå Error downloading audio: ${error.message}`);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * Check and convert audio file format if needed
 * @param {string} filePath - Path to audio file
 * @returns {Promise<{success: boolean, convertedPath?: string, error?: string}>}
 */
async function checkAndConvertAudio(filePath) {
  try {
    log(`üîç Checking audio file format: ${filePath}`);

    // Check file info using file command
    try {
      const fileInfo = execSync(`file "${filePath}"`, { encoding: 'utf8' });
      log(`üìä File info: ${fileInfo.trim()}`);
    } catch (error) {
      log(`‚ö†Ô∏è Could not get file info: ${error.message}`);
    }

    // Try to get audio info with ffprobe (if available)
    let needsConversion = false;
    try {
      const ffprobeOutput = execSync(`ffprobe -v quiet -print_format json -show_format "${filePath}"`, { encoding: 'utf8' });
      const audioInfo = JSON.parse(ffprobeOutput);
      log(`üéµ Audio format: ${audioInfo.format.format_name}`);

      // Check if it's a supported format
      const supportedFormats = ['wav', 'mp3', 'flac', 'm4a', 'ogg'];
      const formatName = audioInfo.format.format_name.toLowerCase();
      needsConversion = !supportedFormats.some(format => formatName.includes(format));

    } catch (error) {
      log(`‚ö†Ô∏è ffprobe not available or failed, attempting direct transcription: ${error.message}`);
      // If ffprobe fails, try direct transcription first
      needsConversion = false;
    }

    if (needsConversion) {
      log(`üîÑ Converting audio to compatible format...`);

      const convertedPath = filePath.replace(/\.[^/.]+$/, '_converted.wav');
      execSync(`ffmpeg -i "${filePath}" -acodec pcm_s16le -ar 16000 "${convertedPath}"`, {
        stdio: 'pipe'
      });

      log(`‚úÖ Audio converted to: ${convertedPath}`);

      return {
        success: true,
        convertedPath: convertedPath
      };
    }

    return {
      success: true,
      convertedPath: filePath // No conversion needed
    };

  } catch (error) {
    logError(`‚ùå Error checking/converting audio: ${error.message}`);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * Transcribe audio file using OpenAI Whisper
 * @param {string} filePath - Path to audio file
 * @returns {Promise<{success: boolean, transcription?: string, error?: string}>}
 */
async function transcribeAudio(filePath) {
  try {
    log(`üé§ Transcribing audio file: ${filePath}`);

    // First check and convert audio if needed
    const conversionResult = await checkAndConvertAudio(filePath);

    let audioFileToUse = filePath;
    if (conversionResult.success && conversionResult.convertedPath) {
      audioFileToUse = conversionResult.convertedPath;
    } else if (!conversionResult.success) {
      log(`‚ö†Ô∏è Audio conversion failed, trying original file: ${conversionResult.error}`);
    }

    // Create a readable stream for the audio file
    const fileStream = (await import('fs')).default.createReadStream(audioFileToUse);

    const transcription = await openai.audio.transcriptions.create({
      file: fileStream,
      model: 'whisper-1',
      language: 'it', // Italian
      prompt: `Trascrizione di una chiamata telefonica aziendale. Vocabolario: ${CUSTOM_VOCABULARY.join(', ')}`,
      response_format: 'text'
    });

    // Clean up converted file if it was created
    if (audioFileToUse !== filePath) {
      try {
        await fs.unlink(audioFileToUse);
        log(`üóëÔ∏è Cleaned up converted file: ${audioFileToUse}`);
      } catch (error) {
        log(`‚ö†Ô∏è Could not clean up converted file: ${error.message}`);
      }
    }

    log(`‚úÖ Transcription completed: ${transcription.length} characters`);

    return {
      success: true,
      transcription: transcription
    };

  } catch (error) {
    logError(`‚ùå Error transcribing audio: ${error.message}`);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * Two-phase analysis system for Squadd sales calls
 * @param {string} transcription - The transcribed text
 * @returns {Promise<{success: boolean, analysis?: object, error?: string}>}
 */
export async function extractKeyPoints(transcription) {
  try {
    log(`üîç Starting two-phase Squadd call analysis...`);

    // PHASE 1: Initial analysis and speaker identification
    const phase1Result = await performPhase1Analysis(transcription);
    if (!phase1Result.success) {
      return phase1Result;
    }

    // Check if call is not substantial or voicemail - skip Phase 2 if so
    if (phase1Result.analysis.call_type === 'non_sostanziosa') {
      log(`‚ö†Ô∏è Non-substantial call detected, skipping Phase 2 coaching`);

      return {
        success: true,
        analysis: {
          ...phase1Result.analysis,
          coaching: null // No coaching for non-substantial calls
        }
      };
    }

    if (phase1Result.analysis.call_type === 'segreteria') {
      log(`üìû Voicemail detected, skipping Phase 2 coaching`);

      return {
        success: true,
        analysis: {
          ...phase1Result.analysis,
          coaching: null // No coaching for voicemail calls
        }
      };
    }

    // PHASE 2: Validation and coaching feedback (only for substantial calls)
    const phase2Result = await performPhase2Coaching(transcription, phase1Result.analysis);
    if (!phase2Result.success) {
      return phase2Result;
    }

    log(`‚úÖ Two-phase analysis completed successfully`);

    return {
      success: true,
      analysis: {
        ...phase1Result.analysis,
        coaching: phase2Result.coaching
      }
    };

  } catch (error) {
    log(`‚ùå Error in two-phase analysis: ${error.message}`);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * Phase 1: Speaker identification and basic call analysis
 */
async function performPhase1Analysis(transcription) {
  try {
    log(`üìã Phase 1: Analyzing speakers and extracting call data...`);

    const completion = await openai.chat.completions.create({
      model: 'gpt-4.1',
      messages: [
        {
          role: 'system',
          content: `Sei un analista esperto di chiamate commerciali per Squadd (CRM SaaS B2B).

CONTESTO: I setter di Squadd chiamano lead aziendali per qualificarli e fissare appuntamenti demo.

IDENTIFICAZIONE SPEAKER:
- SETTER: Si presenta come Squadd, fa domande sul business del lead, propone appuntamenti
- LEAD: Risponde a domande sulla propria azienda, chiede informazioni su Squadd

IMPORTANTE: Rileva il tipo di chiamata:
- SOSTANZIOSA: Dialogo reale tra setter e lead con contenuto commerciale significativo
- NON AVVENUTA: Chiamate brevi, accordi per ricontattarsi, rifiuti immediati, note tecniche, test
- SEGRETERIA: Messaggio registrato di segreteria telefonica, nessuna conversazione reale

ANALIZZA e rispondi in JSON:
{
  "call_type": "sostanziosa/non_sostanziosa/segreteria",
  "call_summary": "Se non sostanziosa, riassunto veloce di cosa √® successo nella chiamata (es: 'Lead e setter si sono accordati per risentirsi domani alle 15:00' oppure 'Lead ha mostrato disinteresse immediato')",
  "speakers": {
    "setter_identified": true/false,
    "lead_identified": true/false,
    "confidence": "Alta/Media/Bassa"
  },
  "call_outcome": {
    "appuntamento_fissato": true/false,
    "motivo_se_non_fissato": "spiegazione breve"
  },
  "lead_info": {
    "azienda": "nome azienda se menzionato",
    "settore": "settore business se chiaro",
    "software_attuale": "software gi√† in uso",
    "team_vendita": "s√¨/no/non chiaro",
    "fa_pubblicit√†": "s√¨/no/non chiaro"
  },
  "sentiment": "Positivo/Neutro/Negativo",
  "note_aggiuntive": "osservazioni importanti"
}`
        },
        {
          role: 'user',
          content: `Analizza questa chiamata Squadd:\n\n${transcription}`
        }
      ],
      temperature: 0.2,
      max_tokens: 800
    });

    const response = completion.choices[0].message.content;
    const analysis = JSON.parse(response);

    log(`‚úÖ Phase 1 completed - speakers identified: ${analysis.speakers.confidence}`);

    return {
      success: true,
      analysis: analysis
    };

  } catch (error) {
    logError(`‚ùå Error in Phase 1 analysis: ${error.message}`);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * Phase 2: BANT analysis and coaching feedback according to Squadd framework
 */
async function performPhase2Coaching(transcription, phase1Analysis) {
  try {
    log(`üéØ Phase 2: BANT analysis and coaching feedback...`);

    const completion = await openai.chat.completions.create({
      model: 'gpt-4.1',
      messages: [
        {
          role: 'system',
          content: `Sei un coach di chiamata esperto per Squadd.
Dal trascritto di chiamata che ricevi, e basandoti sulle regole che hai, dai un verdetto alla chiamata.

# Ruolo e Obiettivo
L'obiettivo √® assicurarsi che il setter segua lo script, faccia un'analisi corretta, e non lasci spazio a dubbi.

Prima di dare qualsiasi feedback (scritto normalmente, a mo' di paragrafo), dai un riassunto:

## Categorie di lead:
üü¢ Categoria 1 - Conosce gi√† il software GoHighLevel oppure uno dei competitor: Delera, Leadfather, Arcanis, Growi, Unique.ai
üîµ Categoria 2 - Usa gi√† software di marketing, CRM o automazioni.
üü° Categoria 3 - Non usa nessuno strumento, o al massimo fogli Google e similari, ma riconsoce di avere un problema ed √® chiaro che sia alla ricerca di una soluzione.
üî¥ Categoria 4 - Non usa strumenti di nessun tipo, e non gli √® chiaro il tipo di problema che ha. L'obiettivo qui √® capire se la persona vuole comunque migliorare la propria azienda/operativit√†.

## B.A.N.T Framework:
Budget -> il budget non deve essere esplicitamente nominato dal setter
Autorit√† -> l'autorit√† solitamente √® impliciata; se per√≤ hai dubbi, dalla per incerta o non esplorata.
Necessit√† -> La necessit√† deriva dall'urgenza e dalla presenza di un problema reale che possiamo risolvere
Tempistica -> La tempistica invece si rivolge alla tempistica di adozione della nostra soluzione; solitamente implicita quando c'√® la necessit√†

## Fasi dello script:
Fase 1 - Introduzione, benvenuto, piacere di conoscerti
Fase 2 - Analisi della situazione ed estrapolazione del bisogno
Fase 3 - Contestualizzo la mia soluzione e la contrappongo ai suoi problemi
Fase 4 - Presa appuntamento

Rispondi in questo formato JSON:
{
  "riassunto": {
    "appuntamento": "‚úÖ Fissato / ‚ùå Non fissato",
    "categoria_lead": "üü¢ Categoria 1 / üîµ Categoria 2 / üü° Categoria 3 / üî¥ Categoria 4",
    "bant": {
      "budget": "‚úÖ presente / ‚ö†Ô∏è incerto / ‚ùå non esplorato",
      "autorit√†": "‚úÖ presente / ‚ö†Ô∏è incerto / ‚ùå non esplorato",
      "necessit√†": "‚úÖ presente / ‚ö†Ô∏è incerto / ‚ùå non esplorato",
      "tempistica": "‚úÖ presente / ‚ö†Ô∏è incerto / ‚ùå non esplorato"
    }
  },
  "coaching_feedback": "Paragrafo di feedback caldo, empatico e contestualizzato per il setter. Massimo 200 parole. Indica passaggi specifici della chiamata. Dai feedback sinceri su cosa migliorare.",
  "fasi_script_seguite": ["Fase 1", "Fase 2", "Fase 3", "Fase 4"],
  "confidenza_analisi": "Alta/Media/Bassa"
}`
        },
        {
          role: 'user',
          content: `Analizza questa chiamata per coaching:

DATI FASE 1:
${JSON.stringify(phase1Analysis, null, 2)}

TRASCRIZIONE COMPLETA:
${transcription}`
        }
      ],
      temperature: 0.3,
      max_tokens: 1000
    });

    const response = completion.choices[0].message.content;
    const coaching = JSON.parse(response);

    log(`‚úÖ Phase 2 completed - coaching generated`);

    return {
      success: true,
      coaching: coaching
    };

  } catch (error) {
    logError(`‚ùå Error in Phase 2 coaching: ${error.message}`);
    return {
      success: false,
      error: error.message
    };
  }
}

/**
 * Clean up temporary audio file
 * @param {string} filePath - Path to file to delete
 */
async function cleanupAudioFile(filePath) {
  try {
    await fs.unlink(filePath);
    log(`üóëÔ∏è Cleaned up audio file: ${filePath}`);
  } catch (error) {
    logError(`‚ö†Ô∏è Error cleaning up audio file: ${error.message}`);
  }
}

/**
 * Complete transcription pipeline
 * @param {string} audioUrl - URL of the recording to transcribe
 * @returns {Promise<{success: boolean, result?: object, error?: string}>}
 */
export async function processRecordingTranscription(audioUrl) {
  let tempFilePath = null;

  try {
    log(`üöÄ Starting transcription pipeline for: ${audioUrl}`);

    // Step 1: Download audio
    const downloadResult = await downloadAudio(audioUrl);
    if (!downloadResult.success) {
      return {
        success: false,
        error: `Download failed: ${downloadResult.error}`
      };
    }

    tempFilePath = downloadResult.filePath;

    // Step 2: Transcribe audio
    const transcriptionResult = await transcribeAudio(tempFilePath);
    if (!transcriptionResult.success) {
      return {
        success: false,
        error: `Transcription failed: ${transcriptionResult.error}`
      };
    }

    // Step 3: Extract key points
    const analysisResult = await extractKeyPoints(transcriptionResult.transcription);
    if (!analysisResult.success) {
      return {
        success: false,
        error: `Analysis failed: ${analysisResult.error}`
      };
    }

    // Step 4: Read the audio file to return buffer for upload
    const audioBuffer = await fs.readFile(tempFilePath);

    // Step 5: Format result
    const result = {
      transcription: transcriptionResult.transcription,
      analysis: analysisResult.analysis,
      audioUrl: audioUrl,
      audioBuffer: audioBuffer,
      processedAt: new Date().toISOString()
    };

    log(`‚úÖ Transcription pipeline completed successfully`);

    return {
      success: true,
      result: result
    };

  } catch (error) {
    logError(`‚ùå Transcription pipeline failed: ${error.message}`);
    return {
      success: false,
      error: error.message
    };

  } finally {
    // Always clean up temp file
    if (tempFilePath) {
      await cleanupAudioFile(tempFilePath);
    }
  }
}

/**
 * Format transcription for GoHighLevel note
 * @param {object} transcriptionResult - Result from processRecordingTranscription
 * @returns {string} Formatted note content
 */
export function formatTranscriptionForGHL(transcriptionResult) {
  const { transcription, analysis, processedAt } = transcriptionResult;

  // Fallback for old format compatibility (only if analysis completely failed)
  if (!analysis) {
    const { keyPoints = [], summary = "Analisi non disponibile" } = transcriptionResult;
    return `üìã Riassunto: ${summary}

üîë Punti chiave:
${keyPoints.map((point, index) => `${index + 1}. ${point}`).join('\n')}

üìù Trascrizione completa:
${transcription}

‚è∞ Elaborata: ${new Date(processedAt).toLocaleString('it-IT')}`;
  }

  // Check if this is voicemail
  if (analysis.call_type === 'segreteria') {
    return `üìµ SEGRETERIA - CLOUDTALK`;
  }

  // Check if this is a non-substantial call
  if (analysis.call_type === 'non_sostanziosa') {
    return `‚úîÔ∏é Risposto - conversazione non avvenuta

üìã Riassunto:
${analysis.call_summary || 'Chiamata tecnica o senza dialogo commerciale'}

üìù Trascrizione:
${transcription}`;
  }

  // Full analysis format for substantial calls
  const { coaching, speakers, call_outcome, lead_info, sentiment } = analysis;

  return `‚úîÔ∏é Conversazione effettuata

${coaching.riassunto.appuntamento}

${coaching.riassunto.categoria_lead}

üìä B.A.N.T. Framework:
‚Ä¢ Budget: ${coaching.riassunto.bant.budget}
‚Ä¢ Autorit√†: ${coaching.riassunto.bant.autorit√†}
‚Ä¢ Necessit√†: ${coaching.riassunto.bant.necessit√†}
‚Ä¢ Tempistica: ${coaching.riassunto.bant.tempistica}

üéØ COACHING FEEDBACK:
${coaching.coaching_feedback}

üìã DETTAGLI CHIAMATA:
‚Ä¢ Sentiment: ${sentiment}
‚Ä¢ Speaker identificati: ${speakers.confidence}
‚Ä¢ Lead: ${lead_info.azienda || 'Non specificato'} (${lead_info.settore || 'Settore non chiaro'})
‚Ä¢ Software attuale: ${lead_info.software_attuale || 'Non specificato'}
‚Ä¢ Team vendita: ${lead_info.team_vendita || 'Non chiaro'}

üîÑ Fasi script seguite: ${coaching.fasi_script_seguite.join(', ')}

üìù Trascrizione completa:
${transcription}

‚è∞ Elaborata: ${new Date(processedAt).toLocaleString('it-IT')}
ü§ñ Confidenza analisi: ${coaching.confidenza_analisi}`;
}

export default {
  processRecordingTranscription,
  formatTranscriptionForGHL,
  extractKeyPoints
};