import 'dotenv/config';
import { searchGHLContactByPhone } from './tests/search-contact-by-phone.js';
import { addNoteToGHLContact } from './tests/add-note.js';
import { processRecordingTranscription, formatTranscriptionForGHL } from '../src/services/transcription-service.js';
import { uploadAudioToConversation } from '../src/services/ghl-conversation-service.js';
import { generateSmartCueCard, sendCueCard } from '../src/services/cuecard-service.js';

/**
 * CloudTalk Webhook ‚Üí GHL Integration Processor
 *
 * Handles the complete flow:
 * 1. Receive CloudTalk webhook
 * 2. Extract phone number (external_number)
 * 3. Search for contact in GHL
 * 4. Add note/activity based on webhook type
 */

export async function processCloudTalkWebhook(webhookPayload, webhookType = 'call-recording-ready') {
  console.log(`üîî Processing CloudTalk webhook: ${webhookType}`);
  console.log('üìã Payload:', JSON.stringify(webhookPayload, null, 2));

  try {
    // Extract phone number from webhook (try multiple field names)
    const phoneNumber = webhookPayload.external_number ||
                       webhookPayload.external_phone ||
                       webhookPayload.phone_number ||
                       webhookPayload.phone ||
                       webhookPayload.caller_number;

    if (!phoneNumber) {
      console.log('üìã Available fields in payload:', Object.keys(webhookPayload));
      throw new Error('‚ùå external_number (or phone field) non trovato nel payload webhook');
    }

    console.log(`üìû Searching GHL contact for phone: ${phoneNumber}`);

    // Step 1: Search for contact in GHL
    const contact = await searchGHLContactByPhone(phoneNumber);

    if (!contact) {
      console.log(`‚ö†Ô∏è Nessun contatto trovato in GHL per il numero ${phoneNumber}`);
      return {
        success: false,
        reason: 'contact_not_found',
        phoneNumber: phoneNumber
      };
    }

    console.log(`‚úÖ Contatto trovato: ${contact.firstName || ''} ${contact.lastName || ''} (ID: ${contact.id})`);

    // Step 2: Process based on webhook type
    let result;

    switch (webhookType) {
      case 'call-recording-ready':
        result = await processRecordingReady(contact, webhookPayload);
        break;

      case 'transcription-ready':
        result = await processTranscriptionReady(contact, webhookPayload);
        break;

      case 'new-tag':
        result = await processNewTag(contact, webhookPayload);
        break;

      case 'new-note':
        result = await processNewNote(contact, webhookPayload);
        break;

      case 'contact-updated':
        result = await processContactUpdate(contact, webhookPayload);
        break;

      case 'call-started':
        result = await processCallStarted(contact, webhookPayload);
        break;

      case 'call-ended':
        result = await processCallEnded(contact, webhookPayload);
        break;

      default:
        throw new Error(`‚ùå Webhook type non supportato: ${webhookType}`);
    }

    console.log('üéâ Webhook processato con successo!');
    return {
      success: true,
      webhookType: webhookType,
      contact: {
        id: contact.id,
        name: `${contact.firstName || ''} ${contact.lastName || ''}`,
        phone: contact.phone
      },
      result: result
    };

  } catch (error) {
    console.error('‚ùå Errore nel processamento webhook:', error.message);
    return {
      success: false,
      error: error.message,
      webhookType: webhookType,
      payload: webhookPayload
    };
  }
}

/**
 * Process call recording ready webhook
 */
async function processRecordingReady(contact, payload) {
  console.log('üéôÔ∏è Processing call recording ready...');

  let noteText = ``;

  let transcriptionResult = null;

  // Try to transcribe the recording
  if (payload.recording_url) {
    console.log('üé§ Attempting to transcribe recording...');

    const transcription = await processRecordingTranscription(payload.recording_url);

    if (transcription.success) {
      console.log('‚úÖ Transcription completed successfully!');
      transcriptionResult = transcription.result;
      
      // Estrai trascrizione e analisi AI
      const transcriptionText = transcription.result?.transcription || '';
      const aiAnalysisResult = transcription.result?.analysis;
      
      // CONTROLLO SEGRETERIA: Trascrizione vuota/breve OPPURE AI rileva segreteria
      const isEmptyTranscription = !transcriptionText || transcriptionText.trim().length < 10;
      const isAIDetectedVoicemail = aiAnalysisResult?.call_type === 'segreteria';
      
      if (isEmptyTranscription || isAIDetectedVoicemail) {
        if (isEmptyTranscription) {
          console.log('üìµ Trascrizione vuota/troppo breve - segreteria');
        } else {
          console.log('ü§ñ AI rilevato segreteria dal contenuto');
        }

        noteText = `üìµ RISPONDE SEGRETERIA - CLOUDTALK`;

        const result = await addNoteToGHLContact(contact.id, noteText);

        // üÜï SEGRETERIA: Invia webhook a GoHighLevel
        let ghlWebhookResult = null;
        try {
          const ghlWebhookUrl = 'https://services.leadconnectorhq.com/hooks/DfxGoORmPoL5Z1OcfYJM/webhook-trigger/873baa5c-928e-428a-ac68-498d954a9ff7';

          const ghlPayload = {
            event_type: 'cloudtalk_call_processed',
            call_type: 'voicemail',
            timestamp: new Date().toISOString(),
            call_id: payload.call_id,
            recording_url: payload.recording_url,
            internal_number: payload.internal_number,
            external_number: payload.external_number,
            agent_id: payload.agent_id,
            contact_id: contact.id,
            detection_method: isEmptyTranscription ? 'empty_transcription' : 'ai_analysis',
            transcription_length: transcriptionText?.length || 0,
            webhook_received_at: new Date().toISOString(),
            source: 'cloudtalk_middleware'
          };

          console.log('üì§ Inviando webhook a GHL per SEGRETERIA');
          console.log('üìã Payload GHL:', JSON.stringify(ghlPayload, null, 2));

          const ghlResponse = await fetch(ghlWebhookUrl, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'User-Agent': 'CloudTalk-Middleware/1.0'
            },
            body: JSON.stringify(ghlPayload)
          });

          if (ghlResponse.ok) {
            const ghlResponseData = await ghlResponse.text();
            ghlWebhookResult = {
              success: true,
              message: 'Segreteria webhook inviato a GoHighLevel con successo',
              response: ghlResponseData
            };
            console.log('‚úÖ Webhook GHL per SEGRETERIA inviato con successo:', ghlResponse.status);
          } else {
            const errorText = await ghlResponse.text();
            throw new Error(`GHL webhook failed: ${ghlResponse.status} - ${errorText}`);
          }

        } catch (ghlWebhookError) {
          console.error('‚ùå GHL Webhook per segreteria failed:', ghlWebhookError.message);

          ghlWebhookResult = {
            success: false,
            error: ghlWebhookError.message,
            message: 'GHL webhook failed but note processing continues'
          };
        }

        return {
          action: 'voicemail_detected',
          noteId: result.id,
          callId: payload.call_id,
          recordingUrl: payload.recording_url,
          transcriptionSuccess: true,
          isVoicemail: true,
          transcriptionText: transcriptionText,
          transcription: transcriptionResult,
          ghlWebhookResult: ghlWebhookResult || { success: false, reason: 'Not processed' }
        };
      }
      
      // Chiamata normale - procedi con upload audio e trascrizione completa
      console.log('üìû Chiamata normale rilevata, procedo con upload completo');

      // Try to upload audio directly to conversation
      console.log('üì§ Attempting to upload audio to GHL conversation...');

      const uploadResult = await uploadAudioToConversation(
        contact.id,
        transcription.result.audioBuffer,
        formatTranscriptionForGHL(transcription.result),
        payload.call_id,
        payload.recording_url
      );

      if (uploadResult.success) {
        console.log('‚úÖ Audio uploaded successfully to conversation!');

        // Add success note
        noteText = `‚úîÔ∏é Conversazione effettuata

${formatTranscriptionForGHL(transcription.result)}`;

        const result = await addNoteToGHLContact(contact.id, noteText);

        return {
          action: 'note_added_with_audio_upload',
          noteId: result.id,
          callId: payload.call_id,
          recordingUrl: payload.recording_url,
          transcriptionSuccess: true,
          audioUploadSuccess: true,
          conversationId: uploadResult.result.conversationId,
          fileUrl: uploadResult.result.fileUrl,
          transcription: transcriptionResult
        };

      } else {
        console.log(`‚ö†Ô∏è Audio upload failed: ${uploadResult.error}`);

        // Fallback to regular note with transcription
        noteText = `‚ö†Ô∏è Upload audio fallito: ${uploadResult.error}

${formatTranscriptionForGHL(transcription.result)}`;
      }

    } else {
      console.log(`‚ö†Ô∏è Transcription failed: ${transcription.error}`);
      noteText = `‚ö†Ô∏è Trascrizione automatica fallita: ${transcription.error}

üìû Call ID: ${payload.call_id}
üîó Recording URL: ${payload.recording_url}
üéß Clicca sul link sopra per ascoltare la registrazione`;
    }
  } else {
    noteText = `‚úÖ Registrazione disponibile per la revisione

üìû Call ID: ${payload.call_id}
üîó Recording URL: ${payload.recording_url}
üéß Clicca sul link sopra per ascoltare la registrazione`;
  }

  const result = await addNoteToGHLContact(contact.id, noteText);

  return {
    action: 'note_added_with_transcription',
    noteId: result.id,
    callId: payload.call_id,
    recordingUrl: payload.recording_url,
    transcriptionSuccess: !!transcriptionResult,
    transcription: transcriptionResult
  };
}

/**
 * Process transcription ready webhook
 */
async function processTranscriptionReady(contact, payload) {
  console.log('üìÑ Processing transcription ready...');

  // Extract transcription text (might be in different fields)
  const transcriptionText = payload.transcription || payload.transcript || payload.text || 'Trascrizione non disponibile';
  const transcriptionUrl = payload.transcription_url || payload.url;

  const noteText = `üìÑ TRASCRIZIONE CLOUDTALK DISPONIBILE

üìû Call ID: ${payload.call_id}
üì± Numero: ${payload.external_number}
üìÖ Timestamp: ${new Date().toLocaleString('it-IT')}

üìù TRASCRIZIONE:
${transcriptionText}

${transcriptionUrl ? `üîó URL Trascrizione: ${transcriptionUrl}` : ''}

‚úÖ Trascrizione completata e disponibile per la revisione`;

  const result = await addNoteToGHLContact(contact.id, noteText);

  return {
    action: 'transcription_added',
    noteId: result.id,
    callId: payload.call_id,
    transcriptionLength: transcriptionText.length,
    hasUrl: !!transcriptionUrl
  };
}

/**
 * Process new tag webhook
 */
async function processNewTag(contact, payload) {
  console.log('üè∑Ô∏è Processing new tag...');

  const noteText = `üè∑Ô∏è NUOVO TAG DA CLOUDTALK

üìû Call ID: ${payload.call_id || 'N/A'}
üè∑Ô∏è Tag: ${payload.tag_name || payload.tag || 'Tag non specificato'}
üì± Numero: ${payload.external_number}
üìÖ Timestamp: ${new Date().toLocaleString('it-IT')}

‚úÖ Tag applicato automaticamente dal sistema CloudTalk`;

  const result = await addNoteToGHLContact(contact.id, noteText);

  return {
    action: 'tag_note_added',
    noteId: result.id,
    tag: payload.tag_name || payload.tag
  };
}

/**
 * Process new note webhook
 */
async function processNewNote(contact, payload) {
  console.log('üìù Processing new note...');

  const noteText = `üìù NUOVA NOTA DA CLOUDTALK

üìû Call ID: ${payload.call_id || 'N/A'}
üìù Nota: ${payload.note_content || payload.content || 'Contenuto non disponibile'}
üë§ Aggiunto da: ${payload.user_name || payload.agent_name || 'Sistema'}
üìÖ Timestamp: ${new Date().toLocaleString('it-IT')}

‚úÖ Nota sincronizzata da CloudTalk`;

  const result = await addNoteToGHLContact(contact.id, noteText);

  return {
    action: 'note_synced',
    noteId: result.id,
    originalNote: payload.note_content || payload.content
  };
}

/**
 * Process contact updated webhook
 */
async function processContactUpdate(contact, payload) {
  console.log('üë§ Processing contact update...');

  const noteText = `üë§ CONTATTO AGGIORNATO SU CLOUDTALK

üìû Call ID: ${payload.call_id || 'N/A'}
üë§ Contatto: ${payload.contact_name || 'N/A'}
üì± Numero: ${payload.external_number}
üîÑ Campi aggiornati: ${payload.updated_fields ? payload.updated_fields.join(', ') : 'Non specificati'}
üìÖ Timestamp: ${new Date().toLocaleString('it-IT')}

‚úÖ Aggiornamento sincronizzato da CloudTalk`;

  const result = await addNoteToGHLContact(contact.id, noteText);

  return {
    action: 'update_logged',
    noteId: result.id,
    updatedFields: payload.updated_fields
  };
}

/**
 * Process call started webhook
 */
async function processCallStarted(contact, payload) {
  console.log('üìû Processing call started...');

  // Step 1: Log chiamata iniziata
  const noteText = `üìû CHIAMATA INIZIATA - CLOUDTALK

üìû Call ID: ${payload.call_id}
üì± Numero chiamante: ${payload.external_number}
üë§ Agente: ${payload.agent_name || payload.agent_id || 'N/A'}
üïê Ora inizio: ${new Date().toLocaleString('it-IT')}
üìã Tipo: ${payload.call_type || 'Non specificato'}

‚è≥ Chiamata in corso...`;

  const noteResult = await addNoteToGHLContact(contact.id, noteText);

  // Step 2: Genera e invia Smart CueCard se abbiamo call_uuid
  let cueCardResult = null;
  if (payload.call_uuid || payload.Call_uuid) {
    try {
      console.log('üéØ Generando Smart CueCard per la chiamata...');
      
      const callUuid = payload.call_uuid || payload.Call_uuid;
      const phoneNumber = payload.external_number;
      
      // Genera CueCard con dati GHL integrati
      const smartCueCard = await generateSmartCueCard(phoneNumber);
      
      // Invia CueCard all'agente
      cueCardResult = await sendCueCard(callUuid, smartCueCard);
      
      console.log('‚úÖ Smart CueCard inviata con successo!');
      
    } catch (cueCardError) {
      console.error('‚ùå Errore generazione Smart CueCard:', cueCardError.message);
      cueCardResult = { success: false, error: cueCardError.message };
    }
  } else {
    console.log('‚ö†Ô∏è Call UUID non trovato, Smart CueCard non inviata');
  }

  return {
    action: 'call_start_logged_with_cuecard',
    noteId: noteResult.id,
    callId: payload.call_id,
    cueCardSent: cueCardResult?.success || false,
    cueCardError: cueCardResult?.error || null
  };
}

/**
 * Process call ended webhook
 */
/**
 * Process call ended webhook
 */
async function processCallEnded(contact, payload) {
  console.log('üìû Processing call ended...');

  const duration = payload.duration || 0;
  const status = payload.call_status || payload.status || 'N/A';
  const callId = payload.call_id;

  // Determina se √® una chiamata senza risposta
  const isNoAnswer = (
    !duration || 
    duration === 0 || 
    duration === 'N/A' ||
    status === 'missed' ||
    status === 'no-answer' ||
    status === 'unanswered' ||
    !callId ||
    callId === 'undefined'
  );

  let noteText;
  let action;

  if (isNoAnswer) {
    // Chiamata senza risposta
    noteText = `üìµ TENTATIVO SENZA RISPOSTA - CLOUDTALK`;
    action = 'no_answer_logged';
  } else {
    // Chiamata effettivamente terminata
    noteText = `üìû CHIAMATA TERMINATA - CLOUDTALK\n\nüìû Call ID: ${callId}\nüì± Numero: ${payload.external_number}\nüë§ Agente: ${payload.agent_name || payload.agent_id || 'N/A'}\n‚è±Ô∏è Durata: ${duration}\nüìä Stato: ${status}\nüïê Ora fine: ${new Date().toLocaleString('it-IT')}\n\n‚úÖ Chiamata completata`;
    action = 'call_end_logged';
  }

  const result = await addNoteToGHLContact(contact.id, noteText);

  // REMOVED: Duplicate GHL webhook sending
  // This was causing DOUBLE webhook sending when used with handleCallEndedWebhook()
  // The GHL webhook forwarding is now handled exclusively in cloudtalk-webhooks.js
  // to prevent duplication issues reported by the user.

  console.log('üìù Note created in GHL, webhook forwarding handled by main webhook handler');

  const webhookResult = {
    success: false,
    skipped: true,
    reason: 'GHL webhook forwarding moved to primary webhook handler to prevent duplication'
  };

  return {
    action: action,
    noteId: result.id,
    callId: callId,
    duration: duration,
    status: status,
    isNoAnswer: isNoAnswer,
    webhookSent: webhookResult
  };
}

// Test function with the webhook payload provided
async function testWebhookProcessor() {
  // Test payload from the call-recording-ready.txt file
  const testPayload = {
    "call_id": 1002226167,
    "recording_url": "https://my.cloudtalk.io/pub/r/MTAwMjIyNjE2Nw%3D%3D/NWYxZDY3MWEzOGY0ZTg3OTQ2ZjRmYzlmZmRmMmQxY2Q2ODU5N2U5ODQyZWE1MTJjNTZlYjVkMmM2Yjk2YjAwMw%3D%3D.wav",
    "internal_number": 40312296109,
    "external_number": "393936815798"
  };

  console.log('üß™ Testing webhook processor with real payload...\n');

  const result = await processCloudTalkWebhook(testPayload, 'call-recording-ready');

  console.log('\nüìä RISULTATO TEST:');
  console.log(JSON.stringify(result, null, 2));
}

// Run test if file is executed directly
if (import.meta.url === `file://${process.argv[1]}`) {
  testWebhookProcessor().catch(error => {
    console.error('üí• Test fallito:', error.message);
    process.exit(1);
  });
}